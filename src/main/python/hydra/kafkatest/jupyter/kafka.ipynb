{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HYDRA Scaling Test 3: Apache Kafka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Goal\n",
    "\n",
    "The goal of this test is to stress the distributed messaging system **Apache Kafka** with increased client load. The general setup is quite simple. A Kafka Producer sends records at a--maximum--pre-defined transmission rate to the Kafka Server (i.e., cluster) which holds on to these records and hands them out to consumer(s). In this test we assume the following considerations:\n",
    "\n",
    "- One Broker.\n",
    "- One Producer with configurable transmission rate.\n",
    "- (N) Consumers (defined by user when launching the test).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "- **Apache Kafka 0.9+**\n",
    "  *Note: this version is required as *kafka-python* (Kafka Python Client) is best used with newer brokers (0.10 or 0.9).*\n",
    "    - Java  \n",
    "    - Zookeeper\n",
    "- **Kafka Python Client** (kafka-python): to create Kafka producers & consumers.\n",
    "\n",
    "  List of available Kafka Clients for most programming languages are available in the following link: https://cwiki.apache.org/confluence/display/KAFKA/Clients#Clients-For0.8.x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## High-Level Workflow\n",
    "\n",
    "- Mesos, Marathon and Hydra (i.e., test environment) configuration parameters can be set in the INI file: `hydra.ini`\n",
    "- Test-related configuration parameters can be specified by the user along the command line when launching the test, e.g., :\n",
    "\n",
    "  `hydra kafka --total_sub_apps=20`\n",
    "\n",
    "- `hydra/kafkatest/runtest.py` is the master python file for the Kafka Test.\n",
    "- The test launches one (1) Publisher (*kafka-pub*) (PUB) and (*n*) Subscribers (*kafka-sub*) (SUB). The number of subscribers is defined when launching the test with the `--total_sub_apps` flag, which defaults to 100 when not specified.\n",
    "- PUB and SUBs have a ZMQ REP (Reply) server to listen to signals and for data (stats) collection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "The following needs to be done in each slave node (where the actual broker/producer/consumer(s) will be launched):\n",
    "\n",
    "**STEP 1: INSTALL APACHE KAFKA**\n",
    "\n",
    "  **1.1 Install Apache Kafka Requirements (Java & ZooKeeper)**\n",
    "\n",
    "    echo \"Install Apache Kafka (Broker)\"\n",
    "    echo \"Update the list of available packages\"\n",
    "    sudo apt-get update\n",
    "    echo \"Install Apache Kafka requirement: Java runtime environment\"\n",
    "    sudo apt-get install default-jre\n",
    "    echo \"Install Apache Zookeeper: used by Kafka to detect failed nodes and elect leaders (among others)\"\n",
    "    sudo apt-get install zookeeperd\n",
    "    echo \"ZooKeeper daemon should start automatically, listening on port 2181\"\n",
    "\n",
    "  **1.2 Check Zookeeper Installation**\n",
    "\n",
    "  To make sure that it is working, connect to it via Telnet:\n",
    "\n",
    "    telnet localhost 2181\n",
    "\n",
    "At the Telnet prompt, type in `ruok` and press ENTER. If everything's fine, ZooKeeper will say `imok` and end the Telnet session.\n",
    "\n",
    "  **1.3 Install Apache Kafka**\n",
    "\n",
    "    echo \"Download and Extract Kafka Binaries\"\n",
    "    echo \"Create Downloads dir to store downloads\".\n",
    "    mkdir -p ~/Downloads\n",
    "    echo \"Download Kafka binaries.\"\"\n",
    "    wget \"http://mirror.cc.columbia.edu/pub/software/apache/kafka/0.8.2.1/kafka_2.11-0.8.2.1.tgz\" -O ~/Downloads/kafka.tgz\n",
    "    echo \"Create a directory called kafka and change to this directory. This will be the base directory of the Kafka installation.\"\n",
    "    mkdir -p ~/kafka && cd ~/kafka\n",
    "    echo \"Extract the archive\"\n",
    "    tar -xvzf ~/Downloads/kafka.tgz --strip 1\n",
    "\n",
    "\n",
    "  **1.4 Configure the Kafka Server (Broker)**\n",
    "\n",
    "    echo \"Open server.properties\"\n",
    "    vim ~/kafka/config/server.properties\n",
    "    echo \"Enable the delete topics feature, which is disabled by default\"\n",
    "\n",
    "Add the following line at the end of the file:\n",
    "\n",
    "    delete.topic.enable = true\n",
    "\n",
    "  **1.5 Start the Kafka Server**\n",
    "\n",
    "    echo \"Run the kafka-server-start.sh script using nohup to start the Kafka server as a background process that is independent of your shell session.\"\n",
    "    nohup ~/kafka/bin/kafka-server-start.sh ~/kafka/config/server.properties > ~/kafka/kafka.log 2>&1 &\n",
    "\n",
    "You now have a Kafka server which is listening on port **9092**.\n",
    "\n",
    "Link to Apache Kafka Installation:\n",
    " https://www.digitalocean.com/community/tutorials/how-to-install-apache-kafka-on-ubuntu-14-04\n",
    "\n",
    "\n",
    "**STEP 2: INSTALL KAFKA PYTHON CLIENT**\n",
    "\n",
    "    echo \"Install Kafka Python Client\"\n",
    "    sudo pip install kafka-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Notes\n",
    "\n",
    "- **Kafka dependency with Zookeeper**\n",
    "\n",
    "Starting from 0.9, all the Zookeeper dependency from the clients has been removed. However, the brokers continue to be heavily depend on Zookeeper for:\n",
    "- Server failure detection.\n",
    "- Data partitioning.\n",
    "- In-sync data replication."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Run the Test?\n",
    "\n",
    "### Execute Kafka Test \n",
    "\n",
    "**MASTER**\n",
    "\n",
    "    source ../venv/bin/activate\n",
    "    cd hydra\n",
    "    pip uninstall -y hydra && pyb install -x run_unit_tests && pyb install --verbose\n",
    "    hydra kafka\n",
    "    \n",
    "### Execute Kafka Tests (batch)\n",
    "\n",
    "    jupyter notebook\n",
    "    #Execute 'run tests & graph' block in notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OTHER RELEVANT COMMANDS**\n",
    "\n",
    "- How to Purge Kafka Queue\n",
    "\n",
    "      bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --delete --topic default-topic\n",
    "\n",
    "- Log Location:\n",
    "\n",
    "        /opt/mesos/slaves/6bcaf7fb-bb8f-4912-aed9-7328597635d8-S0/frameworks/77dc7a7a-3cb7-45ae-9986-7695cba33d3d-0000/executors/g1_kafka-sub.75be999e-245e-11e6-82f3-42010a0a0050/runs/bb4b52dd-825f-410f-8b35-3f6292613083/src/main/scripts\n",
    "\n",
    " or direclty through the Mesos UI, following the path:\n",
    "\n",
    "        Mesos/<App>/sandbox/stderr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kafka Configuration parameters\n",
    "\n",
    "Two values are important (long polling):\n",
    "\n",
    "- `fetch.min.bytes`: The broker will wait for this amount of data to fill BEFORE it sends the response to the consumer client.\n",
    "- `fetch.wait.max.ms`: The broker will wait for this amount of time BEFORE sending a response to the consumer client, unless it has enough data to fill the response (fetch.message.max.bytes)\n",
    "\n",
    "**PUBLISHER CONFIGURATION:**\n",
    "\n",
    "- `batch_size` (given by test param `msg_batch`): This configuration parameter controls the default batch size in [bytes]. It is set to (average_message_length = 14) * (msg_batch)\n",
    "\n",
    "- `acks` (externally configurable)\n",
    "  - 1: wait for leader to write the record to its local log only.\n",
    "  - 0: \n",
    "\n",
    "- `linger_ms` = 5\n",
    "\n",
    "\n",
    "**CONSUMER CONFIGURATION:**\n",
    "\n",
    "- consumer.max_buffer_size=0\n",
    "When subscribing to a topic with a high level of messages that have not been received before, the consumer/client can max out and fail.  Setting an infinite buffer size (zero) allows it to take everything that is available.\n",
    "\n",
    "- group_id (different group id)\n",
    "If all consumers use the same group id, messages in a topic are distributed among those consumers. In other words, each consumer will get a non-overlapping subset of the messages. Having more consumers in the same group increases the degree of parallelism and the overall throughput of consumption. See the next question for the choice of the number of consumer instances. On the other hand, if each consumer is in its own group, each consumer will get a full copy of all messages.\n",
    "\n",
    "**BROKER CONFIGURTION**\n",
    "\n",
    "1\n",
    "2\n",
    "log.retention.ms=5000\n",
    "log.retention.check.interval.ms=10000\n",
    "The first defines that the log is only kept for 5 seconds. The second that checks for logs to delete are done in 10s intervals. This was actually fun to find since mostly the documentation talks about using hours. Some mention doing it at very fine level of minutes.. But it is also possible to do in milliseconds as above. Again, I found that somewhereâ€¦:)\n",
    "\n",
    "bin/kafka-topics.sh --zookeeper localhost:2181 --alter --topic default-topic --config retention.ms=5000 retention.check.interval.ms=10000\n",
    "\n",
    "bin/kafka-topics.sh --zookeeper 127.0.0.1:2181 --alter --topic base-topic --config retention.ms=5000\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relevant Links \n",
    "\n",
    "- **Kafka**\n",
    "    - https://cwiki.apache.org/confluence/display/KAFKA/Index\n",
    "- **How to Install Kafka**\n",
    "    - \n",
    "- **Kafka Python Client**\n",
    "    - https://github.com/dpkp/kafka-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated KAFKA-TEST for n-clients / x-message rate \n",
    "\n",
    "The goal of this test is to stress the distributed messaging system **Apache Kafka** with increased client load. For this purpose, we increase ...\n",
    "\n",
    "For these tests, we had two (2) google cloud instances each with the following specs:\n",
    "\n",
    "- Machine Type: n1-standard-4 (4 vCPUs, 15 GB memory)\n",
    "- CPU platform: Intel Ivy Bridge\n",
    "- OS: Ubuntu 14.04\n",
    "- Kernel: 3.19.0-59-generic\n",
    "\n",
    "## Test Scenario\n",
    "\n",
    "- Version: Kafka 0.9\n",
    "- One (1) Broker\n",
    "- One (1) Topic\n",
    "- No replication\n",
    "- Producers acks = 1 (i.e., wait for leader to write the record to its local log only.)\n",
    "\n",
    "Scenario 1: ack = 1 (1: Wait for leader to write the record to its local log only.)\n",
    "\n",
    "Scenario 2: ack = 0 (0: Producer will not wait for any acknowledgment from the server.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from pprint import pprint, pformat  # NOQA\n",
    "from hydra.kafkatest.runtest import RunTestKAFKA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Options():\n",
    "    test_duration = 10\n",
    "    msg_batch = 1000        \n",
    "    msg_rate= 10000\n",
    "    total_sub_apps = 1\n",
    "    config_file = 'hydra.ini'\n",
    "    keep_running = False\n",
    "    acks = 1\n",
    "    linger_ms = 10\n",
    "    consumer_max_buffer_size = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "global_results = dict()\n",
    "test_instance = None\n",
    "options = Options()\n",
    "runner = RunTestKAFKA(options, False)      #Initialize ALL variables (from CLI options and hydra.ini config file)\n",
    "first_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def RunTest(test_name, first_test):\n",
    "    if not first_test:\n",
    "        runner.start_appserver()\n",
    "        first_test = True\n",
    "    else:\n",
    "        runner.set_options(options)\n",
    "        runner.scale_sub_app()\n",
    "    res = runner.run_test()\n",
    "    print(\"RES = \" + pformat(res))\n",
    "    if not options.total_sub_apps in global_results:\n",
    "         global_results[options.total_sub_apps] = {}\n",
    "    global_results[options.total_sub_apps][test_name] = res\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TEST 1**: Producer Throughput as a function of batch size\n",
    "\n",
    "The following test measures the producer throughput as a function of the batch size.\n",
    "\n",
    "**Code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 2016-06-07 06:55:52,176 h_analyser.py:do_req_resp:67 Timed out waiting for server at 10.10.0.128:16531\n",
      "ERROR 2016-06-07 06:55:52,177 h_analyser.py:get_stats:126 Failed to get stats from task_id=g1_kafka-sub.9dcb1e76-2c7c-11e6-9278-42010a0a0050_PORT16531  Status = False resp = {}\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-67cb77c68d74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mmsg_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmsg_batch_set\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmsg_batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mRunTest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfirst_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mfirst_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-5ad0aa2a8794>\u001b[0m in \u001b[0;36mRunTest\u001b[1;34m(test_name, first_test)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_options\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_sub_app\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"RES = \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_sub_apps\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglobal_results\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/annyz/venv/local/lib/python2.7/site-packages/hydra/kafkatest/runtest.pyc\u001b[0m in \u001b[0;36mrun_test\u001b[1;34m(self, first_run)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaunch_kafka_sub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;31m# Rerun Kafka Test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrerun_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/annyz/venv/local/lib/python2.7/site-packages/hydra/kafkatest/runtest.pyc\u001b[0m in \u001b[0;36mrerun_test\u001b[1;34m(self, options)\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;31m# Fetch all sub client data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch_app_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkafkasub\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult_parser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/annyz/venv/local/lib/python2.7/site-packages/hydra/lib/runtestbase.pyc\u001b[0m in \u001b[0;36mfetch_app_stats\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mfirst_itr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m                 \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m                 \u001b[0mstats2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mha_sub\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_stats\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m                 \u001b[1;31m#  if it's the first read make sure that the sub has stopped receiving data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'msg_cnt'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mstats2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'msg_cnt'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/annyz/venv/local/lib/python2.7/site-packages/hydra/lib/h_analyser.pyc\u001b[0m in \u001b[0;36mget_stats\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    125\u001b[0m             l.error(\"Failed to get stats from task_id=\" + self.task_id +\n\u001b[0;32m    126\u001b[0m                     \"  Status = \" + pformat(status) + \" resp = \" + pformat(resp))\n\u001b[1;32m--> 127\u001b[1;33m         \u001b[1;32massert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'ok'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mitm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mitm\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0municode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# NOQA\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "client_set = [30, 60, 120, 240, 480, 960, 1920]\n",
    "msg_rate = 30000\n",
    "msg_batch_set = [100, 200, 500, 1000, 2000, 5000]\n",
    "\n",
    "first_test = False\n",
    "\n",
    "for client_num in client_set:\n",
    "    options.total_sub_apps = int(client_num / 10)\n",
    "    options.msg_rate = msg_rate\n",
    "    for msg_batch in msg_batch_set:\n",
    "        options.msg_batch = msg_batch\n",
    "        RunTest(msg_batch, first_test)\n",
    "        first_test = True\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, collect data to build tables and graphs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/annyz/venv/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:318: SNIMissingWarning: An HTTPS request has been made, but the SNI (Subject Name Indication) extension to TLS is not available on this platform. This may cause the server to present an incorrect TLS certificate, which can cause validation failures. You can upgrade to a newer version of Python to solve this. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#snimissingwarning.\n",
      "  SNIMissingWarning\n",
      "/home/annyz/venv/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:122: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. You can upgrade to a newer version of Python to solve this. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
      "  InsecurePlatformWarning\n"
     ]
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import operator\n",
    "\n",
    "traces_plot1 = []\n",
    "traces_plot2 = []\n",
    "traces_plot3 = []\n",
    "\n",
    "data_matrix = [['Client #', 'Batch', 'Avrg Tx Rate', 'Avrg Rx Rate', 'Client Loss[%]', 'Failed Clients', 'Total pckts Tx', 'Total pckts Rx']]\n",
    "\n",
    "\n",
    "# For each trace = client count\n",
    "for trace, tests_per_trace in global_results.iteritems():\n",
    "    \n",
    "    average_packet_loss = []\n",
    "    average_packets = []\n",
    "    average_rate = []\n",
    "    average_tx_rate = []\n",
    "    client_count = []\n",
    "    failing_clients = []\n",
    "    failing_clients_rate = []\n",
    "    packet_tx = []\n",
    "    pub_net_rxrate = []\n",
    "    pub_net_txrate = []\n",
    "    \n",
    "    tests_sorted = sorted(tests_per_trace.items(), key=operator.itemgetter(0))\n",
    "\n",
    "    for test in tests_sorted:\n",
    "        average_packet_loss.append(test[1]['average_packet_loss'])\n",
    "        average_packets.append(test[1]['average_packets'])\n",
    "        average_rate.append(test[1]['average_rate'])\n",
    "        average_tx_rate.append(test[1]['average_tx_rate'])            \n",
    "        client_count.append(test[1]['client_count'])\n",
    "        failing_clients.append(test[1]['failing_clients'])\n",
    "        if test[1]['failing_clients'] != 0:            \n",
    "            failing_clients_rate.append(test[1]['failing_clients_rate'])\n",
    "        packet_tx.append(test[1]['packet_tx'])\n",
    "        pub_net_rxrate.append(test[1]['pub_net_rxrate'])\n",
    "        pub_net_txrate.append(test[1]['pub_net_txrate'])\n",
    "        \n",
    "        data_matrix.append([int(test[1]['client_count']), int(test[0]), test[1]['average_tx_rate'], test[1]['average_rate'], test[1]['average_packet_loss'], \n",
    "                           test[1]['failing_clients'], test[1]['packet_tx'], test[1]['average_packets']])\n",
    "        \n",
    "    trace_plot1 = Scatter(\n",
    "      x=msg_batch_set,\n",
    "      y=average_tx_rate, \n",
    "      mode = 'lines+markers',\n",
    "      name = 'client_count = ' + str(trace*10),\n",
    "      line=dict(\n",
    "        shape='spline'\n",
    "        )\n",
    "    )\n",
    "    trace_plot2 = Scatter(\n",
    "      x=msg_batch_set,\n",
    "      y=average_rate,\n",
    "      mode = 'lines+markers',\n",
    "      name = 'client_count = ' + str(trace*10),\n",
    "      line=dict(\n",
    "        shape='spline'\n",
    "        )\n",
    "    )\n",
    "    trace_plot3 = Scatter(\n",
    "      x=msg_batch_set,\n",
    "      y=average_packet_loss, \n",
    "      mode = 'lines+markers',\n",
    "      name = 'client_count = ' + str(trace*10), \n",
    "      line=dict(\n",
    "        shape='spline'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    traces_plot1.append(trace_plot1)\n",
    "    traces_plot2.append(trace_plot2)\n",
    "    traces_plot3.append(trace_plot3)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Graphs with plotly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/annyz/venv/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:122: InsecurePlatformWarning:\n",
      "\n",
      "A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. You can upgrade to a newer version of Python to solve this. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~anny.martinez/24.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data(traces_plot1)\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Average Producer Rate vs. Batch',\n",
    "              xaxis = dict(title = 'Message Batch'),\n",
    "              yaxis = dict(title = 'Average Tx Rate [pps]'),\n",
    "              )\n",
    "\n",
    "# Plot and embed in notebook\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename = 'kafka-throughput-tx-batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/annyz/venv/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:122: InsecurePlatformWarning:\n",
      "\n",
      "A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. You can upgrade to a newer version of Python to solve this. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~anny.martinez/26.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data(traces_plot2)\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Average Client Rate vs. Batch',\n",
    "              xaxis = dict(title = 'Message Batch'),\n",
    "              yaxis = dict(title = 'Average Rx Rate [pps]'),\n",
    "              )\n",
    "\n",
    "# Plot and embed in notebook\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename = 'kafka-throughput-rx-batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/annyz/venv/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:122: InsecurePlatformWarning:\n",
      "\n",
      "A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. You can upgrade to a newer version of Python to solve this. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~anny.martinez/28.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Data(traces_plot3)\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Average Packet Loss vs. Batch',\n",
    "              xaxis = dict(title = 'Message Batch'),\n",
    "              yaxis = dict(title = 'Average Packet Loss [%]'),\n",
    "              )\n",
    "\n",
    "# Plot and embed in notebook\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename = 'kafka-packet-loss-batch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, generate data in a table in markdown format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   Client # |   Batch |   Avrg Tx Rate |   Avrg Rx Rate |   Client Loss[%] |   Failed Clients | Total pckts Tx   | Total pckts Rx   |\n",
      "|-----------:|--------:|---------------:|---------------:|-----------------:|-----------------:|:-----------------|:-----------------|\n",
      "|        960 |     100 |        5627.57 |        565.469 |         0.433111 |                7 | 56276            | 56032            |\n",
      "|         30 |     100 |        5780.59 |       3486.29  |         0        |                0 | 57806            | 57806            |\n",
      "|         30 |     200 |        6505.97 |       6524.21  |         0        |                0 | 65060            | 65060            |\n",
      "|         30 |     500 |        6920.04 |       7075.12  |         0        |                0 | 69201            | 69201            |\n",
      "|         30 |    1000 |        6997.29 |       7029.74  |         0        |                0 | 69973            | 69973            |\n",
      "|         30 |    2000 |        7035.7  |       7063.27  |         0        |                0 | 70359            | 70359            |\n",
      "|         30 |    5000 |        7180.59 |       7211.13  |         0        |                0 | 71806            | 71806            |\n",
      "|         60 |     100 |        5402.98 |       3643.28  |         0        |                0 | 54030            | 54030            |\n",
      "|         60 |     200 |        6263.35 |       6286.16  |         0        |                0 | 62634            | 62634            |\n",
      "|         60 |     500 |        6694.33 |       6576.2   |         0        |                0 | 66944            | 66944            |\n",
      "|         60 |    1000 |        7080.36 |       6792.99  |         0        |                0 | 70804            | 70804            |\n",
      "|         60 |    2000 |        7037.93 |       6772.53  |         0        |                0 | 70380            | 70380            |\n",
      "|         60 |    5000 |        7003.65 |       6722.81  |         0        |                0 | 70037            | 70037            |\n",
      "|        120 |     100 |        5105.74 |       3505.87  |         0        |                0 | 51058            | 51058            |\n",
      "|        120 |     200 |        6489.98 |       5000.97  |         0        |                0 | 64900            | 64900            |\n",
      "|        120 |     500 |        7355.39 |       5130.57  |         0        |                0 | 73554            | 73554            |\n",
      "|        120 |    1000 |        7162.48 |       5048.26  |         0        |                0 | 71625            | 71625            |\n",
      "|        120 |    2000 |        7353.26 |       5027.6   |         0        |                0 | 73533            | 73533            |\n",
      "|        120 |    5000 |        6100.36 |       4658.63  |         0        |                0 | 61004            | 61004            |\n",
      "|        480 |     100 |        5899.89 |       1164.53  |         1.49009  |               15 | 58999            | 58119            |\n",
      "|        480 |     200 |        6525.84 |       1134.03  |         0.348719 |                5 | 65259            | 65031            |\n",
      "|        480 |     500 |        7231.53 |       1164.16  |         4.56227  |              212 | 72316            | 69016            |\n",
      "|        480 |    1000 |        7140.09 |       1166.94  |         2.46217  |               23 | 71401            | 69642            |\n",
      "|        480 |    2000 |        7228.85 |       1138.23  |         0.709657 |                8 | 72289            | 71775            |\n",
      "|        480 |    5000 |        7163.34 |       1136.23  |         0.25466  |                4 | 71634            | 71451            |\n",
      "|        240 |     100 |        5869.46 |       2415.06  |         0.295328 |                5 | 58696            | 58522            |\n",
      "|        240 |     200 |        6599.42 |       2417.18  |         0.492246 |                4 | 65996            | 65671            |\n",
      "|        240 |     500 |        7257.75 |       2385.41  |         0.642668 |                4 | 72579            | 72112            |\n",
      "|        240 |    1000 |        7225.22 |       2356.39  |         0.120958 |                2 | 72253            | 72165            |\n",
      "|        240 |    2000 |        7361.38 |       2410.17  |         0.935601 |                6 | 73614            | 72925            |\n",
      "|        240 |    5000 |        7010.18 |       2374.95  |         0.431538 |                4 | 70102            | 69799            |\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print tabulate(data_matrix, headers=\"firstrow\", tablefmt=\"pipe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  **TEST 2**: Publisher Rate at a fixed transmission rate 10000[pps] as the number of client's increases\n",
    "\n",
    "The following test sets the (maximum) transmission rate to 10000 [pps] and measures consumer rate and packet loss as the number of clients increases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "client_set = [30, 60, 120, 240, 480, 960, 1920, 3840, 7680]\n",
    "msg_rate_set = [30000]\n",
    "\n",
    "first_test = False\n",
    "\n",
    "for client_num in client_set:\n",
    "    options.total_sub_apps = int(client_num / 10)\n",
    "    for msg_rate in msg_rate_set:\n",
    "        options.msg_rate = msg_rate\n",
    "        RunTest(msg_rate, first_test)\n",
    "        first_test = True\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we collect three data-sets:\n",
    "(1) traces_plot1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import operator\n",
    "\n",
    "traces_plot1 = []\n",
    "traces_plot2 = []\n",
    "traces_plot3 = []\n",
    "\n",
    "data_matrix = [['Client #', 'Avrg Tx Rate', 'Avrg Rx Rate', 'Client Loss[%]', 'Failed Clients', 'Total pckts Tx', 'Total pckts Rx']]\n",
    "\n",
    "# For each trace = client count\n",
    "for trace, tests_per_trace in global_results.iteritems():\n",
    "    \n",
    "    average_packet_loss = []\n",
    "    average_packets = []\n",
    "    average_rate = []\n",
    "    average_tx_rate = []\n",
    "    client_count = []\n",
    "    failing_clients = []\n",
    "    failing_clients_rate = []\n",
    "    packet_tx = []\n",
    "    pub_net_rxrate = []\n",
    "    pub_net_txrate = []\n",
    "    \n",
    "    table = [[]]\n",
    "    \n",
    "    tests_sorted = sorted(tests_per_trace.items(), key=operator.itemgetter(0))\n",
    "\n",
    "    for test in tests_sorted:\n",
    "        average_packet_loss.append(test[1]['average_packet_loss'])\n",
    "        average_packets.append(test[1]['average_packets'])\n",
    "        average_rate.append(test[1]['average_rate'])\n",
    "        average_tx_rate.append(test[1]['average_tx_rate'])            \n",
    "        client_count.append(test[1]['client_count'])\n",
    "        failing_clients.append(test[1]['failing_clients'])\n",
    "        if test[1]['failing_clients'] != 0:            \n",
    "            failing_clients_rate.append(test[1]['failing_clients_rate'])\n",
    "        packet_tx.append(test[1]['packet_tx'])\n",
    "        pub_net_rxrate.append(test[1]['pub_net_rxrate'])\n",
    "        pub_net_txrate.append(test[1]['pub_net_txrate'])\n",
    "        \n",
    "        data_matrix.append([int(test[1]['client_count']), test[1]['average_tx_rate'], test[1]['average_rate'], test[1]['average_packet_loss'], \n",
    "                           test[1]['failing_clients'], test[1]['packet_tx'], test[1]['average_packets']])\n",
    "        \n",
    "    trace_plot1 = Scatter(\n",
    "      x=average_tx_rate,\n",
    "      y=average_rate, \n",
    "      mode = 'lines+markers',\n",
    "      name = 'client_count = ' + str(trace*10),\n",
    "      line=dict(\n",
    "        shape='spline'\n",
    "        )\n",
    "    )\n",
    "    trace_plot2 = Scatter(\n",
    "      x=average_tx_rate,\n",
    "      y=average_packet_loss,\n",
    "      mode = 'lines+markers',\n",
    "      name = 'client_count = ' + str(trace*10),\n",
    "      line=dict(\n",
    "        shape='spline'\n",
    "        )\n",
    "    )\n",
    "    trace_plot3 = Scatter(\n",
    "      x=average_tx_rate,\n",
    "      y=failing_clients_rate, \n",
    "      mode = 'lines+markers',\n",
    "      name = 'client_count = ' + str(trace*10), \n",
    "      line=dict(\n",
    "        shape='spline'\n",
    "        )\n",
    "    )\n",
    "\n",
    "    \n",
    "    traces_plot1.append(trace_plot1)\n",
    "    traces_plot2.append(trace_plot2)\n",
    "    traces_plot3.append(trace_plot3)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "from plotly.tools import FigureFactory as FF \n",
    "\n",
    "table = FF.create_table(data_matrix)\n",
    "py.iplot(table, filename='simple_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "print tabulate(data_matrix, headers=\"firstrow\", tablefmt=\"pipe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = Data(traces_plot1)\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Average Client Rate',\n",
    "              xaxis = dict(title = 'Average Tx Rate [pps]'),\n",
    "              yaxis = dict(title = 'Average Rx Rate [pps]'),\n",
    "              )\n",
    "\n",
    "# Plot and embed in notebook\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename = 'kafka-rx-tx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = Data(traces_plot2)\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Average Packet Loss',\n",
    "              xaxis = dict(title = 'Average Tx Rate [pps]'),\n",
    "              yaxis = dict(title = 'Average Packet Loss [%]'),\n",
    "              )\n",
    "\n",
    "# Plot and embed in notebook\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename = 'kafka-loss-tx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = Data(traces_plot3)\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Failing Clients Rate',\n",
    "              xaxis = dict(title = 'Average Tx Rate [pps]'),\n",
    "              yaxis = dict(title = 'Average Failing Clients Rate [pps]'),\n",
    "              )\n",
    "\n",
    "# Plot and embed in notebook\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename = 'kafka-fail-tx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "client_set = [3840]\n",
    "msg_rate_set = [30000]\n",
    "first_test = False\n",
    "\n",
    "for client_num in client_set:\n",
    "    options.total_sub_apps = int(client_num / 10)\n",
    "    for msg_rate in msg_rate_set:\n",
    "        options.msg_rate = msg_rate\n",
    "        RunTest(msg_rate, first_test)\n",
    "        first_test = True\n",
    "        time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "\n",
    "traces_plot4 = []\n",
    "traces_plot5 = []\n",
    "\n",
    "average_packet_loss = []\n",
    "average_packets = []\n",
    "average_rate = []\n",
    "average_tx_rate = []\n",
    "client_count = []\n",
    "failing_clients = []\n",
    "failing_clients_rate = []\n",
    "packet_tx = []\n",
    "pub_net_rxrate = []\n",
    "pub_net_txrate = []\n",
    "\n",
    "trace_x = []\n",
    "    \n",
    "# For each trace = client count\n",
    "for trace, tests_per_trace in global_results.iteritems():\n",
    "    \n",
    "    trace_x.append(trace)\n",
    "    \n",
    "    tests_sorted = sorted(tests_per_trace.items(), key=operator.itemgetter(0))\n",
    "\n",
    "    for test in tests_sorted:\n",
    "        average_packet_loss.append(test[1]['average_packet_loss'])\n",
    "        average_packets.append(test[1]['average_packets'])\n",
    "        average_rate.append(test[1]['average_rate'])\n",
    "        average_tx_rate.append(test[1]['average_tx_rate'])            \n",
    "        client_count.append(test[1]['client_count'])\n",
    "        failing_clients.append(test[1]['failing_clients'])\n",
    "        if test[1]['failing_clients'] != 0:            \n",
    "            failing_clients_rate.append(test[1]['failing_clients_rate'])\n",
    "        packet_tx.append(test[1]['packet_tx'])\n",
    "        pub_net_rxrate.append(test[1]['pub_net_rxrate'])\n",
    "        pub_net_txrate.append(test[1]['pub_net_txrate'])\n",
    "        \n",
    "trace_plot4 = go.Bar(\n",
    "      x=trace_x,\n",
    "      y=average_rate\n",
    "    )\n",
    "\n",
    "trace_plot5 = go.Bar(\n",
    "      x=trace_x,\n",
    "      y=average_packet_loss\n",
    "    )\n",
    "\n",
    "traces_plot4.append(trace_plot4)\n",
    "traces_plot5.append(trace_plot5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = Data(traces_plot4)\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Average Client Rate',\n",
    "              xaxis = dict(title = 'Client Count'),\n",
    "              yaxis = dict(title = 'Average Rx Rate [pps]'),\n",
    "              )\n",
    "\n",
    "# Plot and embed in notebook\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename = 'kafka4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = Data(traces_plot5)\n",
    "# Edit the layout\n",
    "layout = dict(title = 'Average Packet Loss',\n",
    "              xaxis = dict(title = 'Client Count'),\n",
    "              yaxis = dict(title = 'Average Packet Loss [%]'),\n",
    "              )\n",
    "\n",
    "# Plot and embed in notebook\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename = 'kafka5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "runner.delete_all_launched_apps()\n",
    "runner.stop_appserver()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
